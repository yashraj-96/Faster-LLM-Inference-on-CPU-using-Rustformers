# Faster-LLM-Inference-on-CPU-using-Rustformers
To run the open source available LLM models on CPU architecture is challenging, especially in terms of accuracy, hallucinations and the most important part, the execution time. 
